{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99417913",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "697adb03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from: /home/shpark/prj-mlcv/lib/DESRES/DESRES-Trajectory_CLN025-0-protein/CLN025-0-cad.pt\n",
      "Dataset type: <class 'torch.Tensor'>\n",
      "Dataset keys: Not a dict\n",
      "Dataset shape: torch.Size([534743, 45]), dtype: torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Load the CLN025 dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Load the CLN025 dataset\n",
    "dataset_path = \"/home/shpark/prj-mlcv/lib/DESRES/DESRES-Trajectory_CLN025-0-protein/CLN025-0-cad.pt\"\n",
    "print(f\"Loading dataset from: {dataset_path}\")\n",
    "\n",
    "# Load the dataset\n",
    "dataset = torch.load(dataset_path, map_location=\"cpu\")\n",
    "print(f\"Dataset type: {type(dataset)}\")\n",
    "print(f\"Dataset keys: {dataset.keys() if isinstance(dataset, dict) else 'Not a dict'}\")\n",
    "\n",
    "# Examine the structure\n",
    "if isinstance(dataset, dict):\n",
    "    for key, value in dataset.items():\n",
    "        if isinstance(value, torch.Tensor):\n",
    "            print(f\"{key}: shape={value.shape}, dtype={value.dtype}\")\n",
    "        else:\n",
    "            print(f\"{key}: type={type(value)}\")\n",
    "elif isinstance(dataset, torch.Tensor):\n",
    "    print(f\"Dataset shape: {dataset.shape}, dtype: {dataset.dtype}\")\n",
    "else:\n",
    "    print(f\"Dataset structure: {type(dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f446202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline models:\n",
      "  tica-CLN025-jit.pt\n",
      "  tda-CLN025-jit.pt\n",
      "  vde-CLN025-jit.pt\n",
      "  tae-CLN025-jit.pt\n",
      "\n",
      "Your models:\n",
      "  0816_171833-CLN025-jit.pt\n",
      "  0816_171833-CLN025-f32-jit.pt\n",
      "\n",
      "Total CLN025 jit models found: 6\n",
      "  /home/shpark/prj-mlcv/lib/bioemu/opes/model/_baseline_/tica-CLN025-jit.pt\n",
      "  /home/shpark/prj-mlcv/lib/bioemu/opes/model/_baseline_/tda-CLN025-jit.pt\n",
      "  /home/shpark/prj-mlcv/lib/bioemu/opes/model/_baseline_/vde-CLN025-jit.pt\n",
      "  /home/shpark/prj-mlcv/lib/bioemu/opes/model/_baseline_/tae-CLN025-jit.pt\n",
      "  /home/shpark/prj-mlcv/lib/bioemu/opes/model/0816_171833-CLN025-jit.pt\n",
      "  /home/shpark/prj-mlcv/lib/bioemu/opes/model/0816_171833-CLN025-f32-jit.pt\n"
     ]
    }
   ],
   "source": [
    "# Find and list all available jit models for CLN025\n",
    "model_dir = Path(\"/home/shpark/prj-mlcv/lib/bioemu/opes/model\")\n",
    "baseline_dir = model_dir / \"_baseline_\"\n",
    "\n",
    "# Find all CLN025 jit models\n",
    "cln025_jit_models = []\n",
    "\n",
    "# Check baseline models\n",
    "if baseline_dir.exists():\n",
    "    baseline_models = list(baseline_dir.glob(\"*CLN025-jit.pt\"))\n",
    "    cln025_jit_models.extend(baseline_models)\n",
    "    print(\"Baseline models:\")\n",
    "    for model in baseline_models:\n",
    "        print(f\"  {model.name}\")\n",
    "\n",
    "# Check your models  \n",
    "your_models = list(model_dir.glob(\"*CLN025*jit.pt\"))\n",
    "your_models = [m for m in your_models if m.parent == model_dir]  # exclude baseline dir\n",
    "cln025_jit_models.extend(your_models)\n",
    "\n",
    "print(\"\\nYour models:\")\n",
    "for model in your_models:\n",
    "    print(f\"  {model.name}\")\n",
    "\n",
    "print(f\"\\nTotal CLN025 jit models found: {len(cln025_jit_models)}\")\n",
    "for model in cln025_jit_models:\n",
    "    print(f\"  {model}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "395eb498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset structure analysis:\n",
      "Using dataset directly: shape=torch.Size([534743, 45])\n",
      "\n",
      "Input data shape: torch.Size([534743, 45])\n",
      "Input data dtype: torch.float32\n",
      "Input data range: [0.3508, 3.0170]\n",
      "Using subset for testing: torch.Size([1000, 45])\n"
     ]
    }
   ],
   "source": [
    "# Load all models and compute outputs\n",
    "model_outputs = {}\n",
    "model_info = {}\n",
    "\n",
    "# Prepare input data - check what format the models expect\n",
    "print(\"Dataset structure analysis:\")\n",
    "if isinstance(dataset, dict):\n",
    "    # Try common keys that might contain the coordinate data\n",
    "    input_data = None\n",
    "    for key in ['pos', 'positions', 'coords', 'coordinates', 'cad']:\n",
    "        if key in dataset:\n",
    "            input_data = dataset[key]\n",
    "            print(f\"Using '{key}' as input data: shape={input_data.shape}\")\n",
    "            break\n",
    "    \n",
    "    if input_data is None:\n",
    "        # Use the first tensor we find\n",
    "        for key, value in dataset.items():\n",
    "            if isinstance(value, torch.Tensor):\n",
    "                input_data = value\n",
    "                print(f\"Using '{key}' as input data: shape={input_data.shape}\")\n",
    "                break\n",
    "elif isinstance(dataset, torch.Tensor):\n",
    "    input_data = dataset\n",
    "    print(f\"Using dataset directly: shape={input_data.shape}\")\n",
    "\n",
    "print(f\"\\nInput data shape: {input_data.shape}\")\n",
    "print(f\"Input data dtype: {input_data.dtype}\")\n",
    "print(f\"Input data range: [{input_data.min():.4f}, {input_data.max():.4f}]\")\n",
    "\n",
    "# Take a subset for faster testing (first 1000 frames if available)\n",
    "if len(input_data) > 1000:\n",
    "    input_subset = input_data[:1000]\n",
    "    print(f\"Using subset for testing: {input_subset.shape}\")\n",
    "else:\n",
    "    input_subset = input_data\n",
    "    print(f\"Using full dataset: {input_subset.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26bf527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import additional dependencies for compute_cv_values\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "def compute_cv_values(\n",
    "    mlcv_model,\n",
    "    cad_torch,\n",
    "    model_type,\n",
    "    reference_cad=None,\n",
    "    batch_size=10000,\n",
    "):\n",
    "    \"\"\"Compute CV values from the model with optional sign flipping using batch processing.\"\"\"\n",
    "    dataset = TensorDataset(cad_torch)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    print(f\"Computing CV values in batches of {batch_size}...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        sample_batch = next(iter(dataloader))[0]\n",
    "        sample_output = mlcv_model(sample_batch)\n",
    "        output_dim = sample_output.shape[1]\n",
    "    cv_batches = torch.zeros((len(cad_torch), output_dim)).to(cad_torch.device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (batch_data,) in enumerate(tqdm(\n",
    "            dataloader,\n",
    "            desc=\"Computing CV values\",\n",
    "            total=len(dataloader),\n",
    "            leave=False,\n",
    "        )):\n",
    "            batch_cv = mlcv_model(batch_data)\n",
    "            start_idx = batch_idx * batch_size\n",
    "            end_idx = start_idx + batch_cv.shape[0]  # Handle last batch size correctly\n",
    "            cv_batches[start_idx:end_idx] = batch_cv\n",
    "    \n",
    "    cv = cv_batches.detach().cpu().numpy()\n",
    "    MLCV_DIM = cv.shape[1]\n",
    "    \n",
    "    print(f\"CV computation complete. Shape: {cv.shape}\")\n",
    "    \n",
    "    if model_type == \"mlcv\":\n",
    "        # Normalize CV values for MLCV\n",
    "        cv_normalized = np.zeros_like(cv)\n",
    "        \n",
    "        for cv_dim in range(MLCV_DIM):\n",
    "            cv_dim_val = cv[:, cv_dim]\n",
    "            cv_range_min, cv_range_max = cv_dim_val.min(), cv_dim_val.max()\n",
    "            cv_range_mean = (cv_range_min + cv_range_max) / 2.0\n",
    "            cv_range = (cv_range_max - cv_range_min) / 2.0\n",
    "            cv_normalized[:, cv_dim] = (cv_dim_val - cv_range_mean) / cv_range\n",
    "        \n",
    "        cv = cv_normalized\n",
    "        \n",
    "    # Additional sign flipping based on reference structure\n",
    "    if reference_cad is not None:\n",
    "        with torch.no_grad():\n",
    "            ref_cv = mlcv_model(torch.from_numpy(reference_cad).to(cad_torch.device))\n",
    "            ref_cv = ref_cv.detach().cpu().numpy()\n",
    "        \n",
    "        # Normalize reference CV the same way\n",
    "        if model_type == \"mlcv\":\n",
    "            ref_cv_normalized = np.zeros_like(ref_cv)\n",
    "            for cv_dim in range(MLCV_DIM):\n",
    "                ref_cv_dim_val = ref_cv[:, cv_dim]\n",
    "                cv_dim_val = cv[:, cv_dim]\n",
    "                cv_range_min, cv_range_max = cv_dim_val.min(), cv_dim_val.max()\n",
    "                cv_range_mean = (cv_range_min + cv_range_max) / 2.0\n",
    "                cv_range = (cv_range_max - cv_range_min) / 2.0\n",
    "                ref_cv_normalized[:, cv_dim] = (ref_cv_dim_val - cv_range_mean) / cv_range\n",
    "            ref_cv = ref_cv_normalized\n",
    "        \n",
    "        # Flip signs to ensure reference CV is positive\n",
    "        for cv_dim in range(MLCV_DIM):\n",
    "            if ref_cv[0, cv_dim] < 0:\n",
    "                cv[:, cv_dim] = -cv[:, cv_dim]\n",
    "                print(f\"Flipped sign for CV dimension {cv_dim} to ensure positive reference value\")\n",
    "    \n",
    "    return cv\n",
    "\n",
    "print(\"âœ“ compute_cv_values function defined\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bioemu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
